### Resources

* [Day 1 Livestream with Paige Bailey ‚Äì 5-Day Gen AI Intensive Course | Kaggle](https://www.youtube.com/watch?v=kpRyiJUUFxY&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es&index=2)
* [(217) Discord | #5dgai-q-and-a | Kaggle](https://discord.com/channels/1101210829807956100/1303438695143178251)
* [Kaggle GenAI, Nov 11, 2024 (Day 1): Tips &amp; Tricks - YouTube](https://www.youtube.com/watch?v=v5bhhJ9FD60&t=24s)

---


### **![üéí](https://fonts.gstatic.com/s/e/notoemoji/15.1/1f392/32.png) Today‚Äôs Assignments**

1. Complete the Intro Unit ‚Äì ‚ÄúFoundational Large Language Models & Text Generation‚Äù, which is:

* [Optional] Listen to the summary [podcast episode](https://notifications.googleapis.com/email/redirect?t=AFG8qyW3IQUSJ4aZ00WZ99pcvpPhrZinGdg-Vrg03JjPwhOq7vm7DcZUVo5X3omYeQYLfnwroi1sM4Y-i3DhGjyi1VIMhG1A6auIKPRhfWvxq5e2vbol8-dW8D6aoOLTBAuLwMwNL3yMYS6l63F_kn0js0m3ussVkfUoaRt8t-BoB0oLP6eBGkNUjVGa0X08DDCA2hoWdXRsn1hWLT7IOEnZKfjeDv5nIXpy4rxhwdb7VO9wgHqHSfu056OY8FLJ1lg0aZv3&r=eJzLKCkpKLbS16_MLy0p1UtK1c8NdMlxjooq9q_MBwCWDwpF&s=ALHZ2r4jo7Q9IXrLM8UQAM7aVMSi) for this unit (created by [NotebookLM](https://notifications.googleapis.com/email/redirect?t=AFG8qyWAYhFrZ_G9QS8ZzPpFwrL5E9vQw2zQCm-yB9yzVCKHD2CtBCzKtbN6lhHZRMdD88j05AMmIQ8vLcnWMNfWqUAoOHpbLKmDEI7ie8noEgVrvfSc5zMS-RpDdayxLwWhIIJCckIblsJ58iwuoWM3ggyVTWyOhWBhCGEcQxmYDIzpZ5Ms3xCybupdcOsWMb6tGKCQTwx64qg32Lz51zzMNPSwXaz7b6xQM4e6Fnr3rH0ZUrgqX_qPQEzWDNLb6Q3S-t7K&r=eJzLKCkpKLbS18_LL0lNys_PzsnVS8_PT89J1UvOz9W3zy_KTM_MS8yJL0pNSy1KLbLNAKtXNXIDovLyciTFqkbGagU5mbaGABuTHe8&s=ALHZ2r4YoLwS9EQgpkZx3LTKqGzH)).
* Read the [‚ÄúFoundational Large Language Models &amp; Text Generation‚Äù whitepaper](https://notifications.googleapis.com/email/redirect?t=AFG8qyXJwPUOd5W8MnTbaU7bmwY-Eh8-QfC1-CnfA2l8H84KBOtM6nbNLIfWVt21oKXTIAcNXLtIGgkdUvYmTfKVitsjPHyFlRF7ZkY7zWnMxUjReOGvFtCyOVGar1kHY7VTmrTACZ-IAzOCf-_TO_ON-LmdIQYyQMlbM9b6B9o6skKjrESlLJ4Ib--mAO1cgFX_0z0Xa2DucBgpcuK451cV9Pa8PwyjASGoXgxCVkZbf7A4VCbWjIHtL7XOPj9ZjhEJotqP&r=eJwdyVEOgCAIANATof_dhiWiC4EZjY7f1vt9I8Lvo9bMLBcyC5XTVs0xgxydNnR7tGFMUxQQWYDaIOgNYFLa_3yx_hrt&s=ALHZ2r6YuJ-KZt5ATL3VAK-kJTzv).

2. Complete Unit 1 ‚Äì ‚ÄúPrompt Engineering‚Äù, which is:

* [Optional] Listen to the summary [podcast episode](https://notifications.googleapis.com/email/redirect?t=AFG8qyUW0QmuvhMzMPrPcsBjI7w7cGdB-VA3OJkt5aipoKefkGHDeVGycvfpXsw16o8wVUC7xpVMY3n7MZ7HuKqhpkz80smQTDy-p4wIvsgsqvL-m38iPGWSmTfhOrGEcuFT2fWxsrSOr2-XybzHczFPwL3PXfUZdrfigd4s--EiS_iN_oTfzHYkN9jxlAbo2AiXr9Espq_2HSPeN_jLi5FsDkFm0xQkcCufDUiHwZND4zH-idXU1dfLmABBq15gjeL06k3M&r=eJzLKCkpKLbS16_MLy0p1UtK1XeLz_Aycq00cfJLBgCTQwmk&s=ALHZ2r5H1n0xV9_4_fYe1Ap04Pb7) for this unit (created by NotebookLM).
* Read the [‚ÄúPrompt Engineering‚Äù whitepaper](https://notifications.googleapis.com/email/redirect?t=AFG8qyXkrAOcW4VBTKPFlr1Zl5BbDeEF4Y0bFnpNhucLL-A16TF6qYJlHT8HuCq3VBSI8jj66TQV3_egd8FEActj3AIsadnz7HZ6ElGAbNq4dEnaJwSe7DP1ZT853NkMyHeRAPxBpPylTduQwMhngcqP95U4-Qq1RCdXBv2snhilgPruDahhxHg-nIqtSV6FwVvrnmbVm3EWqb8JvvPdIfKmek1WVUFi5swqPLtKQs-Z5AYl5F-8Y_9ChnKWV7XNKsMfNC50&r=eJwFwUEKwCAMBMAXae79jZQlBmtc0kC-78zM5P-IVFVfQ_VDf8-WmpbgIKIxzmY2uJoDYa4XDAUUJg&s=ALHZ2r7FDTM3Y0vF8ki2Gx_1cTg8).
* Complete [this code lab](https://notifications.googleapis.com/email/redirect?t=AFG8qyVjsumFWilqCc6CGLM4fwcMjngketvdNturjuXtqr0CSsId4NAtrCleJoHExtDmvWQGa6IG6B1IoX9HBL2U5wV3bjC3PpdSeuRGX632U6bnja8OG_Qrt2K1eZAvWFqYqEtZYqQ-57w6Oorg_8LAMOcJSN0B4cm4sydDdu1ckIA4sjlTlW05i8DtKKE4pqYngbD2xyH-yA95_dfgsHulN1YNrhWhP7YS8-qzZUP4UeX_Q_8hlRpvGnIFM5who_PxjhEI&r=eJwFwVEKwCAIANATlex3t5ESi3KKCbLb996IsPMCZGZdyLypNhVo2gkEfc0zyAk6_uUp5ioW8-MLJ5cUMw&s=ALHZ2r5tHey7Z5jDhxCJnJNKXWB1) on Kaggle where you‚Äôll learn prompting fundamentals. Make sure you [phone verify](https://notifications.googleapis.com/email/redirect?t=AFG8qyUKjAsCBwBpqvGlaFhriR_UR3X18L7pcQTc5Y-P67gUsQbn8lEtx3cp0qSw-O7MKmepDKH_74nHyCteXnODWX6RUORpXkpg37_LnNPZytnMH60MctYKNbrjHsNReUdf7o___WA0eXxYFHE4qyyi6dO3IuBhi4cV1UAggb-eiYHF6tKOl4RNg9yQg4NHJtuZxo76BY_H4hWXUhbmxQ0Ff3fuhC-2i3TRRAjR4rkPtPcFsWGoYfx-GT9oUTHcS1XDnR2H&r=eJzLKCkpKLbS1y8vL9fLTkxPz0nVS87P1S9OLSnJzEsvBgC6DwvX&s=ALHZ2r4sz_BNTc3kBSashKv2yA_-) your account before starting, it's necessary for the code labs.


---



### **![üí°](https://fonts.gstatic.com/s/e/notoemoji/15.1/1f4a1/32.png)What You‚Äôll Learn**

Today you‚Äôll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You‚Äôll also get trained in the art of prompt engineering for optimal LLM interaction.

The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts


---



![1732077475439](image/Notes/1732077475439.png)

![1732077533874](image/Notes/1732077533874.png)

![1732077557836](image/Notes/1732077557836.png)


---

# YT Notes Takeaways

## Kaggle Generative AI Intensive Course - Day 1 Notes

## Overview

- **Course Duration**: 5 days (November 11‚Äì15)
- **Sponsor**: Kaggle and the Gemini Team (Google)
- **Focus**: Generative AI fundamentals
  - Foundational models
  - Prompt engineering
  - Embeddings and vector databases
  - AI agents and domain-specific models
  - MLOps for model maintenance

## Key Features of the Course

1. **Daily Assignments**: White papers, podcasts, and code labs.
2. **Live Q&A Sessions**: Expert guest speakers from Google and DeepMind.
3. **Interactive Learning**:
   - Access to Google Gemini APIs.
   - Code labs for practical experience.
4. **Resources**:
   - A dedicated Discord channel for discussions and queries.

---

## Topics Covered on Day 1

### 1. Foundational Models

- **Definition**: Large language models trained on massive data sets.
- **Applications**: From text generation to multimodal outputs (e.g., images, videos).
- **Technological Advancements**:
  - Gemini models now support OpenAI API compatibility.
  - Smaller models like Gemini Flash AP offer cost-efficient, high-speed inference.

### 2. Prompt Engineering

- **Importance**: Enhances the effectiveness of model responses.
- **Techniques**:
  - Zero-shot prompting.
  - Few-shot prompting.
  - Chain of Thought (CoT) prompting for reasoning-based tasks.
  - JSON and Enum modes for structured outputs.

### 3. Reinforcement Learning with Human Feedback (RLHF)

- **Purpose**: Align models with human preferences and safety guidelines.
- **Mechanism**:
  - Collect feedback via user interactions (e.g., thumbs up/down).
  - Reward and penalize responses based on human preference data.

### 4. Accelerating Inference

- **Techniques**:
  - Quantization: Reducing precision to improve efficiency.
  - Distillation: Transferring knowledge from large models to smaller ones.
  - Flash Attention: Optimizing computations for faster results.

### 5. Evaluation of Models

- **Methods**:
  - Classical metrics like BLEU and ROUGE.
  - Auto-evaluation using LLMs as raters.
  - Fine-tuning task-specific performance.

---

## Code Labs Highlights

1. **Setup**:

   - Install the Generative AI SDK.
   - Authenticate using Kaggle secrets for API keys.
2. **Prompts**:

   - Single-turn interactions.
   - Multi-turn conversational interfaces.
3. **Generation Parameters**:

   - **Temperature**: Controls randomness.
   - **Top-K and Top-P**: Limit token sampling scope.
   - **Output length**: Caps the maximum tokens in the response.
4. **Prompt Engineering**:

   - **Enum Mode**: Restrict responses to predefined categories.
   - **Chain of Thought**: Encourage step-by-step reasoning.
   - **JSON Mode**: Generate structured data for programmatic use.
5. **Advanced Features**:

   - Code generation and execution.
   - Multi-step workflows using the ReAct framework.

---

## Pop Quiz Questions and Answers

### 1. Which setting controls randomness in token selection?

- **Answer**: Temperature.

### 2. Which technique does NOT accelerate inference?

- **Answer**: Fine-tuning.

### 3. Unique characteristic of Gemini models?

- **Answer**: 2 million token context window.

### 4. How does RLHF improve models?

- **Answer**: Uses a reward model to incentivize human-preferred responses.

### 5. Which technique enhances reasoning via intermediate steps?

- **Answer**: Chain of Thought (CoT) prompting.

### 6. Minimum GPU memory needed for a 3B parameter model (standard float precision)?

- **Answer**: 12 GB.

---

## Key Takeaways

- Gemini models and prompt engineering offer powerful tools for building generative AI applications.
- RLHF and distillation methods play key roles in improving model performance.
- Evaluation techniques ensure relevance and accuracy for specific tasks.

---
