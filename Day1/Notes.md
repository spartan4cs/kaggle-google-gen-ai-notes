### ðŸ“š **Resources**

* [Day 1 Livestream with Paige Bailey â€“ 5-Day Gen AI Intensive Course | Kaggle](https://www.youtube.com/watch?v=kpRyiJUUFxY&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es&index=2)
* [(217) Discord | #5dgai-q-and-a | Kaggle](https://discord.com/channels/1101210829807956100/1303438695143178251)
* [Kaggle GenAI, Nov 11, 2024 (Day 1): Tips &amp; Tricks - YouTube](https://www.youtube.com/watch?v=v5bhhJ9FD60&t=24s)
* [Gemini API  |  Google AI for Developers](https://ai.google.dev/gemini-api/docs)
* [Google AI Studio](https://aistudio.google.com/prompts/new_chat)
* [https://www.kaggle.com/code/aakash404/day-1-prompting/](https://www.kaggle.com/code/aakash404/day-1-prompting/)
* [paper foundational llm](https://chatgpt.com/share/673ee02f-fae8-8011-b403-b8a7116308bf)

### **âš™ï¸ Setup Instructions**

* Sign up for a [Kaggle account](https://notifications.googleapis.com/email/redirect?t=AFG8qyUgOy4PEZdjz8xQEpDv5W1HfN9I953Pnm1U93hjjkG6aATHS-IgWuBr4pGy7nq3RqjQys9bWzbuw2-mvNrGP84Fxdg66zLFcxdgVZqRy9NdslJaqK2PIvfMnS5sOjueISH3kt7TLfvtwp7O0tjRdA1yGqyp-ruaqKUq3jic51MdQnes8X5xzJeZ0iydkhndWmcCI3H24sx1FEeBdBd5TiWuHysxP-K04p0T43qyBQfKnzGyQojIvpexd59gOEbQsC3t&r=eJzLKCkpKLbS1y8vL9fLTkxPz0nVS87P1QcAZ1kIZg&s=ALHZ2r6nD87O1ESSzJ9vOEUik5fA) and [learn how Notebooks work](https://notifications.googleapis.com/email/redirect?t=AFG8qyXK9FwaoFn-rIOtEZgHxHHa55HxVBaYyKPyMs4VuvWK3LAT9dirzk5_rBEochDXb_ENAHGT98mNgNbp0MM4Ctcw9U_d5SjeNurHJUlLQyMWi-RQuhHnOqgHD1vQ22G_TAHOEe32gdpVXu4JvEfvW8YUiqaATnhRAlWApJcnllUnJAvX3oKY5ghPiOG0XIubYlubjmQ-RzEt8hAR7vwMSzaz2DLdnODcXGclDdUxfyihc810VpKQCo7hmbd3YfAIiCOc&r=eJzLKCkpKLbS1y8vL9fLTkxPz0nVS87P1U_JTy7Wz8svSU3Kz88uBgAGng4S&s=ALHZ2r5tpjdIxcpldZLTwO3LOGFl). Make sure to [phone verify](https://notifications.googleapis.com/email/redirect?t=AFG8qyXu3bsNDChhT7GKfogCqZVWSEvpjeBAObJ6HUTC6PQ7oKxnJa4sin1XcqV3G8gMoccRQKpJ0l14lOv0s122xVWMkidhz4Z-Ua5tPtgKP_dL7J3iIzOcl25Ud25F91jLv1RPdI1fpXBvQM2GB8mC7u08elWmM9Gv-PdPU0PeCHhm-Rb2sszeeWsSHfSo7ezfaygo5YtpKautg9jNKLZqdMtmB-kJFNsCyIMxQbc_kEggXBPw7AkiulLZbJXTRhCXcNYG&r=eJzLKCkpKLbS1y8vL9fLTkxPz0nVS87P1S9OLSnJzEsvBgC6DwvX&s=ALHZ2r7wwm68KjP6KIKfvRebJr4l) your account, itâ€™s necessary for the courseâ€™s code labs.
* Sign up for an  [AI Studio](https://aistudio.google.com/prompts/new_chat) account and ensure you can generate an [API key](https://aistudio.google.com/app/apikey).
* Sign up for a Discord account and join us on the [Kaggle Discord server](https://discord.com/invite/kaggle). We have 3 channels dedicated to this event:
  * [#5dgai-general-chat](https://discord.com/channels/1101210829807956100/1303438361117069363): find official course announcements and livestream recordings.
  * [#5dgai-introductions](https://discord.com/channels/1101210829807956100/1303438635772809311): introduce yourself and meet other participants from around the world.
  * [#5dgai-q-and-a](https://discord.com/channels/1101210829807956100/1303438695143178251): ask questions and kick off discussions about the assignments.
* Please note that if you would like to post on other channels on the Kaggle Discord you will need to link your Kaggle account to Discord here: [https://kaggle.com/discord/confirmation](https://notifications.googleapis.com/email/redirect?t=AFG8qyVHuM_-pwYCadOIbSSb5IwK86MiD5OW62EFLXpmNUMZhzBlNzUQERqVYcR-0d1FJRtlvT7RdxlIw0MhSBAGAHw-mwaMNQ9pG_-jw2z7sICZwkrQNOZgDdTY1k7WlcHVc1_2IUSW7_eEBnus6DP5OVy0BT7T27Z7xARr1_X0_wRXGxcQX8NHPphyzOvc5V5fnq_CYM3FM5S_2t5yIUG6zZFf3vX2DeJayFXJrS96yc4zg-U7mNMeDubDu2V1CAYXZhVL&r=eJzLKCkpKLbS189OTE_PSdVLzs_VT8ksTs4vStFPzs9LyyzKTSzJzM8DACM-DvM&s=ALHZ2r5reTAp10f09_iwpGWxuOoI)

---

### **![ðŸŽ’](https://fonts.gstatic.com/s/e/notoemoji/15.1/1f392/32.png) Todayâ€™s Assignments**

1. Complete the Intro Unit â€“ â€œFoundational Large Language Models & Text Generationâ€, which is:

* [Optional] Listen to the summary [podcast episode](https://www.youtube.com/watch?v=mQDlCZZsOyo&feature=youtu.be) for this unit (created by [NotebookLM](https://notebooklm.google.com/?original_referer=https:%2F%2Fwww.google.com%23&pli=1)).
* Read the [â€œFoundational Large Language Models &amp; Text Generationâ€ whitepaper](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation).

2. Complete Unit 1 â€“ â€œPrompt Engineeringâ€, which is:

* [Optional] Listen to the summary [podcast episode](https://www.youtube.com/watch?v=F_hJ2Ey4BNc&feature=youtu.be) for this unit (created by NotebookLM).
* Read the [â€œPrompt Engineeringâ€ whitepaper](https://www.kaggle.com/whitepaper-prompt-engineering).
* Complete [this code lab](https://www.kaggle.com/code/markishere/day-1-prompting) on Kaggle where youâ€™ll learn prompting fundamentals. Make sure you [phone verify](https://www.kaggle.com/settings) your account before starting, it's necessary for the code labs.

---

### **![ðŸ’¡](https://fonts.gstatic.com/s/e/notoemoji/15.1/1f4a1/32.png)What Youâ€™ll Learn**

Today youâ€™ll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. Youâ€™ll also get trained in the art of prompt engineering for optimal LLM interaction.

The code lab will walk you through getting started with the Gemini API and cover several prompt techniques and how different parameters impact the prompts

---

![1732077475439](image/Notes/1732077475439.png)

![1732077533874](image/Notes/1732077533874.png)

![1732077557836](image/Notes/1732077557836.png)

---

# â–¶ï¸ YT Notes Takeaways

Here are the detailed notes for **Day 1** of the Kaggle Generative AI Intensive Course. The notes are structured using proper markdown with examples for clarity.

---

# **Day 1: Kaggle Generative AI Intensive Course**

## **Overview**

* This is a **5-day virtual course** aimed at teaching generative AI concepts and practical applications.
* Day 1 focuses on:
  * **Foundational Models**
  * **Prompt Engineering**
* Key components:
  * **Guest Speakers** discussing cutting-edge generative AI topics.
  * **Daily Assignments** using white papers and podcasts.
  * **Code Labs and Demos** to learn hands-on skills.
  * **Q&A Sessions** to resolve participant queries.
  * **Pop Quiz** to test knowledge.

---

## **Key Topics for Day 1**

### **1. Foundational Models**

#### What are Foundational Models?

* These are large, pre-trained models that serve as a base for various applications.
* Examples:
  * **Language Models (LLMs)** like GPT, Gemini, and others.
  * Multimodal models (handling text, image, audio, and video).
* Applications include:
  * **Machine Translation**
  * **Question-Answering**
  * **Text Summarization**
  * **Embedding Generation**

#### Training and Tuning

1. **Supervised Fine-Tuning (SFT):**
   * Using high-quality labeled data for task-specific training.
   * Example: Training a chatbot to answer customer support queries.
2. **Reinforcement Learning with Human Feedback (RLHF):**
   * Aligning models with human preferences.
   * Example:
     * Users provide feedback via thumbs up/down.
     * This feedback is used to train a **Reward Model** to improve responses.
3. **Inference Optimization Techniques:**
   * **Quantization** : Reducing model precision to speed up inference.
   * **Distillation** : Training smaller models using outputs of larger models.
   * **Speculative Decoding** : Accelerating token generation during inference.

---

### **2. Prompt Engineering**

#### What is Prompt Engineering?

* The art of designing input prompts to guide model outputs effectively.

#### Types of Prompting

1. **Zero-Shot Prompting:**
   * No examples provided; just an instruction.
   * Example:
     ```plaintext
     Prompt: Classify the sentiment of this review: "I loved the product!"
     Output: Positive
     ```
2. **Few-Shot Prompting:**
   * Providing examples to guide the model.
   * Example:
     ```plaintext
     Prompt:
     Review: "The movie was fantastic!" -> Sentiment: Positive
     Review: "The food was terrible." -> Sentiment: Negative
     Review: "I had a great time." -> Sentiment:
     Output: Positive
     ```
3. **Chain of Thought Prompting:**
   * Asking the model to think step-by-step for better reasoning.
   * Example:
     ```plaintext
     Prompt: When I was 4 years old, my sister was twice my age. Now Iâ€™m 20. How old is my sister?
     Output:
     Step 1: When I was 4, my sister was 8 (twice my age).
     Step 2: The age difference is 4 years.
     Step 3: Now that Iâ€™m 20, my sister is 24.
     Answer: 24
     ```
4. **Structured Output Prompting (e.g., JSON mode):**
   * Ensures outputs are in a specific format.
   * Example:
     ```plaintext
     Prompt: Provide a summary of the book in JSON format.
     Output:
     {
       "title": "The Great Gatsby",
       "author": "F. Scott Fitzgerald",
       "summary": "A tragic story of love, wealth, and societal expectations."
     }
     ```

#### Parameters to Tune Outputs

* **Temperature** :
* Controls randomness in token selection.
* Example:
  * Low temperature: Predictable outputs.
  * High temperature: Diverse and creative outputs.
* **Top-K and Top-P Sampling** :
* Filters the token pool during generation.
* Top-K: Selects top K most probable tokens.
* Top-P: Selects tokens based on cumulative probability.

---

## **Day 1 Activities**

### **A. Code Labs**

* Participants work on **Colab Notebooks** to learn:

  1. **Single-Turn Prompting** :

  * Sending a single query and receiving a response.
  * Example:
    ```plaintext
    Prompt: Explain AI to me like Iâ€™m 5 years old.
    Output: AI is like a robot brain that helps computers solve problems and learn new things.
    ```

  1. **Conversational Applications** :

  * Creating chat interfaces that retain memory.
  * Example:
    ```plaintext
    Prompt 1: My name is Alex.
    Output 1: Nice to meet you, Alex!
    Prompt 2: What's my name?
    Output 2: Your name is Alex.
    ```

  1. **Working with Multiple Models** :

  * Comparing small and large models, such as Gemini 1.5 Flash.

  1. **Using Parameters** :

  * Modifying output length, temperature, and sampling methods.

  1. **Prompt Engineering Techniques** :

  * Chain of Thought prompting for complex tasks.

### **B. Q&A Highlights**

1. **Grounding with Google Search:**
   * Integrating search results to make model answers more reliable.
2. **OpenAI Compatibility:**
   * Gemini models are now compatible with OpenAI APIs with minimal code changes.
3. **Multimodal Outputs:**
   * Combining text, video, and images for rich, interactive outputs.

---

### **Pop Quiz Questions**

1. **What controls randomness in token prediction?**

   **Answer:** Temperature
2. **Which is not an inference optimization technique?**

   **Answer:** Fine-Tuning
3. **What is unique about Gemini models?**

   **Answer:** 2 million token context window.
4. **How does RLHF improve models?**

   **Answer:** By incentivizing human-preferred responses.
5. **Which technique enhances reasoning via intermediate steps?**

   **Answer:** Chain of Thought Prompting
6. **Minimum GPU memory for a 3B parameter model?**

   **Answer:** 12 GB

---
